{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "760bc496-c6ea-4e34-af32-43275d4ecc79",
   "metadata": {},
   "source": [
    "## HLA-A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc38385-4fc9-4345-9cbc-e7a5b2023e03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Bio import AlignIO\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "# Function to calculate Shannon entropy for a given column in the alignment\n",
    "def shannon_entropy(column):\n",
    "    counts = Counter(column)\n",
    "    probabilities = [freq / len(column) for freq in counts.values()]\n",
    "    entropy = -sum(p * math.log2(p) if p > 0 else 0 for p in probabilities)\n",
    "    return entropy\n",
    "\n",
    "# Function to normalize entropy based on the number of residues (with and without gaps)\n",
    "def normalize_entropy(entropies, num_residues):\n",
    "    max_entropy = math.log2(num_residues)\n",
    "    normalized_entropies = [e / max_entropy for e in entropies]\n",
    "    return normalized_entropies\n",
    "\n",
    "# Load the aligned sequences using Biopython\n",
    "aligned_sequences = AlignIO.read('aligned_A.fasta', 'fasta')\n",
    "\n",
    "# Convert aligned sequences to a list of strings for easier processing\n",
    "aligned_seq_str = [str(record.seq) for record in aligned_sequences]\n",
    "\n",
    "# Transpose the alignment for column-wise processing\n",
    "transposed_alignment = np.array([list(seq) for seq in aligned_seq_str]).T\n",
    "\n",
    "# Calculate entropy for each column\n",
    "entropies = [shannon_entropy(column) for column in transposed_alignment]\n",
    "\n",
    "# Find the number of unique residues (with and without gaps)\n",
    "unique_residues_with_gaps = len(set(''.join([''.join(column) for column in transposed_alignment])))\n",
    "unique_residues_without_gaps = len(set(''.join([''.join(column) for column in transposed_alignment])) - set('-'))\n",
    "\n",
    "# Normalized entropy values\n",
    "normalized_entropies_with_gaps = normalize_entropy(entropies, unique_residues_with_gaps)\n",
    "normalized_entropies_without_gaps = normalize_entropy(entropies, unique_residues_without_gaps)\n",
    "\n",
    "# Print entropy values for each position\n",
    "for i, (entropy, norm_with_gaps, norm_without_gaps) in enumerate(zip(entropies, normalized_entropies_with_gaps, normalized_entropies_without_gaps)):\n",
    "    print(f\"Position {i+1}: Entropy = {entropy:.4f}, Normalized (with gaps) = {norm_with_gaps:.4f}, Normalized (without gaps) = {norm_without_gaps:.4f}\")\n",
    "\n",
    "# Overall normalized entropy\n",
    "overall_entropy_with_gaps = np.mean(normalized_entropies_with_gaps)\n",
    "overall_entropy_without_gaps = np.mean(normalized_entropies_without_gaps)\n",
    "\n",
    "print(f\"\\nOverall Normalized Entropy (with gaps): {overall_entropy_with_gaps:.4f}\")\n",
    "print(f\"Overall Normalized Entropy (without gaps): {overall_entropy_without_gaps:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558d9cb6-c182-4662-bc78-4594fcfdeefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import AlignIO\n",
    "from collections import Counter\n",
    "\n",
    "# Define ANSI escape sequences for colors\n",
    "RED = '\\033[91m'\n",
    "ENDC = '\\033[0m'\n",
    "\n",
    "# Load the alignment file\n",
    "alignment = AlignIO.read(\"aligned_A.fasta\", \"fasta\")\n",
    "\n",
    "# Generate consensus sequence list\n",
    "consensus_seq = []\n",
    "for i in range(len(alignment[0])):\n",
    "    column = [record.seq[i] for record in alignment]  # Extract the column\n",
    "    most_common = Counter(column).most_common(1)[0][0]\n",
    "    consensus_seq.append(most_common)\n",
    "\n",
    "# Initialize the colored consensus sequence as an empty string\n",
    "colored_consensus = \"\"\n",
    "\n",
    "# Iterate over the consensus sequence and add color\n",
    "for position, amino_acid in enumerate(consensus_seq, start=1):\n",
    "    # Highlight every 10th amino acid\n",
    "    if position % 10 == 0:\n",
    "        colored_consensus += RED + amino_acid + ENDC\n",
    "    else:\n",
    "        colored_consensus += amino_acid\n",
    "\n",
    "    # Every 100th character (including gaps), insert a newline\n",
    "    if position % 50 == 0:\n",
    "        colored_consensus += '\\n'\n",
    "\n",
    "# Print the colored consensus sequence\n",
    "print(colored_consensus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c88dc1c-390e-44a5-856d-caba061e513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import AlignIO\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "# Function to calculate probability distribution for a given column\n",
    "def probability_distribution(column):\n",
    "    counts = Counter(column)\n",
    "    total = sum(counts.values())\n",
    "    return {residue: count / total for residue, count in counts.items()}\n",
    "\n",
    "# Function to calculate cross-entropy between two columns\n",
    "def cross_entropy(dist1, dist2):\n",
    "    residues = set(dist1.keys()).union(dist2.keys())\n",
    "    return -sum(dist1.get(residue, 0) * math.log2(dist2.get(residue, 0) if dist2.get(residue, 0) > 0 else 1) for residue in residues)\n",
    "\n",
    "# Load the aligned sequences\n",
    "try:\n",
    "    aligned_sequences = AlignIO.read('aligned_A.fasta', 'fasta')\n",
    "except Exception as e:\n",
    "    print(f\"Error loading alignment file: {e}\")\n",
    "    raise\n",
    "\n",
    "# Convert aligned sequences to a list of strings\n",
    "aligned_seq_str = [str(record.seq) for record in aligned_sequences]\n",
    "\n",
    "# Check if the alignment is correctly loaded\n",
    "if not aligned_seq_str:\n",
    "    print(\"No sequences found in the alignment.\")\n",
    "else:\n",
    "    print(f\"Loaded {len(aligned_seq_str)} sequences.\")\n",
    "\n",
    "# Transpose the alignment for column-wise processing\n",
    "transposed_alignment = np.array([list(seq) for seq in aligned_seq_str]).T\n",
    "\n",
    "# Calculate probability distributions for each column\n",
    "prob_distributions = [probability_distribution(column) for column in transposed_alignment]\n",
    "\n",
    "# Calculate cross-entropy for each pair of columns\n",
    "cross_entropy_values = np.zeros((len(prob_distributions), len(prob_distributions)))\n",
    "for i, dist1 in enumerate(prob_distributions):\n",
    "    for j, dist2 in enumerate(prob_distributions):\n",
    "        cross_entropy_values[i, j] = cross_entropy(dist1, dist2)\n",
    "\n",
    "# Normalize cross-entropy values\n",
    "max_entropy = math.log2(len(prob_distributions))\n",
    "normalized_cross_entropy = cross_entropy_values / max_entropy\n",
    "\n",
    "# Print cross-entropy values\n",
    "print(\"Cross-Entropy Values:\")\n",
    "for i in range(len(cross_entropy_values)):\n",
    "    for j in range(len(cross_entropy_values)):\n",
    "        print(f\"Cross-Entropy between positions {i+1} and {j+1}: {cross_entropy_values[i, j]:.4f}, Normalized: {normalized_cross_entropy[i, j]:.4f}\")\n",
    "\n",
    "# Create a heatmap using Plotly\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=cross_entropy_values,\n",
    "    x=[f\"Pos {i+1}\" for i in range(len(cross_entropy_values))],\n",
    "    y=[f\"Pos {j+1}\" for j in range(len(cross_entropy_values))],\n",
    "    colorscale='Viridis'))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Cross-Entropy Heatmap between Positions in Protein Alignment',\n",
    "    xaxis_nticks=36,\n",
    "    yaxis_nticks=36,    \n",
    "    width=1000,  \n",
    "    height=1000,  \n",
    "    margin=dict(l=100, r=100, t=100, b=100)  \n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3eb894-7d68-4f03-958a-cf7f3bf8a881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Bio import AlignIO\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import plotly.graph_objects as go\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "def encode_sequences(sequences, alphabet='ACDEFGHIKLMNPQRSTVWY-'):\n",
    "    char_to_int = {c: i for i, c in enumerate(alphabet)}\n",
    "    encoded_seqs = [[char_to_int.get(char, -1) for char in seq] for seq in sequences]\n",
    "    return np.array(encoded_seqs, dtype=int)\n",
    "\n",
    "def calculate_mi_for_position(encoded_seqs, i):\n",
    "    X = np.delete(encoded_seqs, i, axis=1)\n",
    "    y = encoded_seqs[:, i]\n",
    "    mi_score = mutual_info_classif(X, y, discrete_features=True)\n",
    "    return np.insert(mi_score, i, 0)  # Insert 0 at the ith position for the diagonal\n",
    "\n",
    "def main():\n",
    "    aligned_sequences = AlignIO.read(\"aligned_A.fasta\", \"fasta\")\n",
    "    sequences = [str(record.seq) for record in aligned_sequences]\n",
    "    encoded_seqs = encode_sequences(sequences)\n",
    "\n",
    "    num_features = encoded_seqs.shape[1]\n",
    "    mi_matrix = np.zeros((num_features, num_features))\n",
    "\n",
    "    with Pool(processes=cpu_count()) as pool:\n",
    "        results = pool.starmap(calculate_mi_for_position, [(encoded_seqs, i) for i in range(num_features)])\n",
    "\n",
    "    for i, mi_scores in enumerate(results):\n",
    "        mi_matrix[i, :] = mi_scores\n",
    "\n",
    "    # Normalize the mutual information matrix using MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    mi_matrix_normalized = scaler.fit_transform(mi_matrix)\n",
    "\n",
    "    # Create a heatmap using Plotly\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=mi_matrix_normalized,\n",
    "        x=[f\"Pos {i+1}\" for i in range(num_features)],\n",
    "        y=[f\"Pos {i+1}\" for i in range(num_features)],\n",
    "        colorscale='Portland',  # Changed to Viridis for better color contrast\n",
    "        zmin=0, zmax=1  # Set the scale from 0 to 1\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='MinMax Scaled Mutual Information Heatmap',\n",
    "        xaxis_title=\"Position\",\n",
    "        yaxis_title=\"Position\",\n",
    "        width=900,\n",
    "        height=900\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839e6d10-0c18-475c-8065-bfb4934f8179",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Bio import AlignIO\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "# Function to calculate the probability distribution for a column\n",
    "def probability_distribution(column):\n",
    "    total = len(column)\n",
    "    return {residue: count / total for residue, count in Counter(column).items()}\n",
    "\n",
    "# Function to calculate mutual information\n",
    "def mutual_information(distribution1, distribution2, joint_distribution):\n",
    "    mi = 0.0\n",
    "    for key1, prob1 in distribution1.items():\n",
    "        for key2, prob2 in distribution2.items():\n",
    "            joint_prob = joint_distribution.get((key1, key2), 0)\n",
    "            if joint_prob > 0:\n",
    "                mi += joint_prob * math.log2(joint_prob / (prob1 * prob2))\n",
    "    return mi\n",
    "\n",
    "# Load aligned sequences\n",
    "aligned_sequences = AlignIO.read(\"aligned_A.fasta\", \"fasta\")\n",
    "\n",
    "# Convert aligned sequences to a list of strings\n",
    "seq_str = [str(record.seq) for record in aligned_sequences]\n",
    "\n",
    "# Transpose to get columns\n",
    "transposed = np.array([list(seq) for seq in seq_str]).T\n",
    "\n",
    "# Calculate mutual information for each pair of positions\n",
    "num_positions = len(transposed)\n",
    "mi_matrix = np.zeros((num_positions, num_positions))\n",
    "\n",
    "for i in range(num_positions):\n",
    "    for j in range(num_positions):  # Compute for all pairs\n",
    "        dist1 = probability_distribution(transposed[i])\n",
    "        dist2 = probability_distribution(transposed[j])\n",
    "        joint_dist = Counter(zip(transposed[i], transposed[j]))\n",
    "        mi = mutual_information(dist1, dist2, joint_dist)\n",
    "        mi_matrix[i, j] = mi\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"Mutual information calculations completed for {i + 1} positions.\")\n",
    "\n",
    "# Create a heatmap using Plotly\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=mi_matrix,\n",
    "    x=[f\"Pos {i+1}\" for i in range(num_positions)],\n",
    "    y=[f\"Pos {j+1}\" for i in range(num_positions)],\n",
    "    colorscale='Cividis'))  # Using Cividis colorscale\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Mutual Information Heatmap between Positions in Protein Alignment',\n",
    "    xaxis_title=\"Position\",\n",
    "    yaxis_title=\"Position\",\n",
    "    width=800,\n",
    "    height=800)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b65814-f8d5-4551-8dfc-408d872ceaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import AlignIO\n",
    "from collections import Counter\n",
    "\n",
    "# Define ANSI escape sequences for colors\n",
    "RED = '\\033[91m'\n",
    "ENDC = '\\033[0m'\n",
    "\n",
    "# Load the alignment file\n",
    "alignment = AlignIO.read(\"aligned_B.fasta\", \"fasta\")\n",
    "\n",
    "# Generate consensus sequence list\n",
    "consensus_seq = []\n",
    "for i in range(len(alignment[0])):\n",
    "    column = [record.seq[i] for record in alignment]  # Extract the column\n",
    "    most_common = Counter(column).most_common(1)[0][0]\n",
    "    consensus_seq.append(most_common)\n",
    "\n",
    "# Initialize the colored consensus sequence as an empty string\n",
    "colored_consensus = \"\"\n",
    "\n",
    "# Iterate over the consensus sequence and add color\n",
    "for position, amino_acid in enumerate(consensus_seq, start=1):\n",
    "    # Highlight every 10th amino acid\n",
    "    if position % 10 == 0:\n",
    "        colored_consensus += RED + amino_acid + ENDC\n",
    "    else:\n",
    "        colored_consensus += amino_acid\n",
    "\n",
    "    # Every 100th character (including gaps), insert a newline\n",
    "    if position % 50 == 0:\n",
    "        colored_consensus += '\\n'\n",
    "\n",
    "# Print the colored consensus sequence\n",
    "print(colored_consensus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3595ee81-8c6d-44bd-9bfa-02be931581c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import AlignIO\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "# Function definitions (shannon_entropy, normalize_entropy) remain the same as before\n",
    "\n",
    "# Load the aligned sequences using Biopython\n",
    "aligned_sequences = AlignIO.read('aligned_A.fasta', 'fasta')\n",
    "\n",
    "# Convert aligned sequences to a list of strings\n",
    "aligned_seq_str = [str(record.seq) for record in aligned_sequences]\n",
    "\n",
    "# Transpose the alignment for column-wise processing\n",
    "transposed_alignment = np.array([list(seq) for seq in aligned_seq_str]).T\n",
    "\n",
    "# Calculate entropy for each column\n",
    "entropies = [shannon_entropy(column) for column in transposed_alignment]\n",
    "\n",
    "# Find the number of unique residues (with and without gaps)\n",
    "unique_residues_with_gaps = len(set(''.join([''.join(column) for column in transposed_alignment])))\n",
    "unique_residues_without_gaps = len(set(''.join([''.join(column) for column in transposed_alignment])) - set('-'))\n",
    "\n",
    "# Normalized entropy values\n",
    "normalized_entropies_with_gaps = normalize_entropy(entropies, unique_residues_with_gaps)\n",
    "normalized_entropies_without_gaps = normalize_entropy(entropies, unique_residues_without_gaps)\n",
    "\n",
    "# Function to find top 10 positions with lowest entropy excluding gaps\n",
    "def find_lowest_entropy_positions(normalized_entropies, alignment, num_positions=10):\n",
    "    sorted_positions = sorted(range(len(normalized_entropies)), key=lambda i: normalized_entropies[i])\n",
    "    lowest_entropy_positions = []\n",
    "    for pos in sorted_positions:\n",
    "        if len(lowest_entropy_positions) >= num_positions:\n",
    "            break\n",
    "        column = set(alignment[pos])\n",
    "        # Exclude positions that are only gaps\n",
    "        if '-' in column:\n",
    "            column.remove('-')\n",
    "        if column:  # If there are amino acids in the column\n",
    "            lowest_entropy_positions.append((pos, normalized_entropies[pos], column))\n",
    "    return lowest_entropy_positions\n",
    "\n",
    "# Find top 10 positions for both cases\n",
    "top_positions_with_gaps = find_lowest_entropy_positions(normalized_entropies_with_gaps, transposed_alignment)\n",
    "top_positions_without_gaps = find_lowest_entropy_positions(normalized_entropies_without_gaps, transposed_alignment)\n",
    "\n",
    "# Print the positions, their normalized entropy values, and the corresponding amino acids\n",
    "print(\"Top 10 positions with lowest entropy (including gaps):\")\n",
    "for pos, entropy, amino_acids in top_positions_with_gaps:\n",
    "    print(f\"Position {pos + 1}: Normalized Entropy = {entropy:.4f}, Amino Acids = {', '.join(amino_acids)}\")\n",
    "\n",
    "print(\"\\nTop 10 positions with lowest entropy (excluding gaps):\")\n",
    "for pos, entropy, amino_acids in top_positions_without_gaps:\n",
    "    print(f\"Position {pos + 1}: Normalized Entropy = {entropy:.4f}, Amino Acids = {', '.join(amino_acids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091fe134-8137-42f6-8192-e3fbd84d4dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "from Bio import AlignIO\n",
    "\n",
    "# Function to encode amino acids as integers\n",
    "def encode_amino_acids(seq, aa_index):\n",
    "    return np.array([aa_index.get(aa, -1) for aa in seq])\n",
    "\n",
    "# Function to calculate the covariance matrix using CuPy\n",
    "def calculate_covariance_matrix(alignment, aa_index):\n",
    "    num_sequences, seq_length = alignment.shape\n",
    "    aa_freq = cp.zeros((seq_length, len(aa_index)))  # Using CuPy\n",
    "\n",
    "    for i in range(seq_length):\n",
    "        for aa, idx in aa_index.items():\n",
    "            aa_freq[i, idx] = cp.sum(alignment[:, i] == idx) / num_sequences\n",
    "\n",
    "    covariance_matrix = cp.zeros((seq_length, seq_length))\n",
    "    for i in range(seq_length):\n",
    "        for j in range(seq_length):\n",
    "            if i != j:\n",
    "                for idx1 in aa_index.values():\n",
    "                    for idx2 in aa_index.values():\n",
    "                        p_ij = cp.sum((alignment[:, i] == idx1) & (alignment[:, j] == idx2)) / num_sequences\n",
    "                        p_i = aa_freq[i, idx1]\n",
    "                        p_j = aa_freq[j, idx2]\n",
    "                        covariance_matrix[i, j] += p_ij - p_i * p_j\n",
    "    return covariance_matrix\n",
    "\n",
    "# Load the alignment using BioPython and NumPy\n",
    "alignment = AlignIO.read(\"aligned_A.fasta\", \"fasta\")\n",
    "aa_index = {aa: idx for idx, aa in enumerate('ACDEFGHIKLMNPQRSTVWY')}  # Map amino acids to indices\n",
    "encoded_alignment = np.array([encode_amino_acids(rec.seq, aa_index) for rec in alignment])\n",
    "\n",
    "# Transfer the encoded alignment to CuPy for GPU computation\n",
    "alignment_gpu = cp.array(encoded_alignment)\n",
    "\n",
    "# Calculate the covariance matrix using CuPy\n",
    "cov_matrix_gpu = calculate_covariance_matrix(alignment_gpu, aa_index)\n",
    "\n",
    "# Convert the covariance matrix back to NumPy for plotting\n",
    "cov_matrix_np = cp.asnumpy(cov_matrix_gpu)\n",
    "\n",
    "# Plotting the heatmap\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cov_matrix_np, cmap='hot', interpolation='nearest')\n",
    "plt.title(\"Covariance Matrix Heatmap\")\n",
    "plt.xlabel(\"Residue Position\")\n",
    "plt.ylabel(\"Residue Position\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1c5514-a7b4-4038-972f-fd166ce51a0d",
   "metadata": {},
   "source": [
    "## HLA-B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f14603-cede-45b3-979a-73c1c4889349",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import AlignIO\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "# Function to calculate Shannon entropy for a given column in the alignment\n",
    "def shannon_entropy(column):\n",
    "    counts = Counter(column)\n",
    "    probabilities = [freq / len(column) for freq in counts.values()]\n",
    "    entropy = -sum(p * math.log2(p) if p > 0 else 0 for p in probabilities)\n",
    "    return entropy\n",
    "\n",
    "# Function to normalize entropy based on the number of residues (with and without gaps)\n",
    "def normalize_entropy(entropies, num_residues):\n",
    "    max_entropy = math.log2(num_residues)\n",
    "    normalized_entropies = [e / max_entropy for e in entropies]\n",
    "    return normalized_entropies\n",
    "\n",
    "# Load the aligned sequences using Biopython\n",
    "aligned_sequences = AlignIO.read('aligned_B.fasta', 'fasta')\n",
    "\n",
    "# Convert aligned sequences to a list of strings for easier processing\n",
    "aligned_seq_str = [str(record.seq) for record in aligned_sequences]\n",
    "\n",
    "# Transpose the alignment for column-wise processing\n",
    "transposed_alignment = np.array([list(seq) for seq in aligned_seq_str]).T\n",
    "\n",
    "# Calculate entropy for each column\n",
    "entropies = [shannon_entropy(column) for column in transposed_alignment]\n",
    "\n",
    "# Find the number of unique residues (with and without gaps)\n",
    "unique_residues_with_gaps = len(set(''.join([''.join(column) for column in transposed_alignment])))\n",
    "unique_residues_without_gaps = len(set(''.join([''.join(column) for column in transposed_alignment])) - set('-'))\n",
    "\n",
    "# Normalized entropy values\n",
    "normalized_entropies_with_gaps = normalize_entropy(entropies, unique_residues_with_gaps)\n",
    "normalized_entropies_without_gaps = normalize_entropy(entropies, unique_residues_without_gaps)\n",
    "\n",
    "# Print entropy values for each position\n",
    "for i, (entropy, norm_with_gaps, norm_without_gaps) in enumerate(zip(entropies, normalized_entropies_with_gaps, normalized_entropies_without_gaps)):\n",
    "    print(f\"Position {i+1}: Entropy = {entropy:.4f}, Normalized (with gaps) = {norm_with_gaps:.4f}, Normalized (without gaps) = {norm_without_gaps:.4f}\")\n",
    "\n",
    "# Overall normalized entropy\n",
    "overall_entropy_with_gaps = np.mean(normalized_entropies_with_gaps)\n",
    "overall_entropy_without_gaps = np.mean(normalized_entropies_without_gaps)\n",
    "\n",
    "print(f\"\\nOverall Normalized Entropy (with gaps): {overall_entropy_with_gaps:.4f}\")\n",
    "print(f\"Overall Normalized Entropy (without gaps): {overall_entropy_without_gaps:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ececb0b9-d313-418b-9137-444fe7fbce4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import AlignIO\n",
    "from collections import Counter\n",
    "\n",
    "# Define ANSI escape sequences for colors\n",
    "RED = '\\033[91m'\n",
    "ENDC = '\\033[0m'\n",
    "\n",
    "# Load the alignment file\n",
    "alignment = AlignIO.read(\"aligned_C.fasta\", \"fasta\")\n",
    "\n",
    "# Generate consensus sequence list\n",
    "consensus_seq = []\n",
    "for i in range(len(alignment[0])):\n",
    "    column = [record.seq[i] for record in alignment]  # Extract the column\n",
    "    most_common = Counter(column).most_common(1)[0][0]\n",
    "    consensus_seq.append(most_common)\n",
    "\n",
    "# Initialize the colored consensus sequence as an empty string\n",
    "colored_consensus = \"\"\n",
    "\n",
    "# Iterate over the consensus sequence and add color\n",
    "for position, amino_acid in enumerate(consensus_seq, start=1):\n",
    "    # Highlight every 10th amino acid\n",
    "    if position % 10 == 0:\n",
    "        colored_consensus += RED + amino_acid + ENDC\n",
    "    else:\n",
    "        colored_consensus += amino_acid\n",
    "\n",
    "    # Every 100th character (including gaps), insert a newline\n",
    "    if position % 50 == 0:\n",
    "        colored_consensus += '\\n'\n",
    "\n",
    "# Print the colored consensus sequence\n",
    "print(colored_consensus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eff1199-2084-48f1-bff9-ed1c32d8c42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import AlignIO\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "# Function definitions (shannon_entropy, normalize_entropy) remain the same as before\n",
    "\n",
    "# Load the aligned sequences using Biopython\n",
    "aligned_sequences = AlignIO.read('aligned_B.fasta', 'fasta')\n",
    "\n",
    "# Convert aligned sequences to a list of strings\n",
    "aligned_seq_str = [str(record.seq) for record in aligned_sequences]\n",
    "\n",
    "# Transpose the alignment for column-wise processing\n",
    "transposed_alignment = np.array([list(seq) for seq in aligned_seq_str]).T\n",
    "\n",
    "# Calculate entropy for each column\n",
    "entropies = [shannon_entropy(column) for column in transposed_alignment]\n",
    "\n",
    "# Find the number of unique residues (with and without gaps)\n",
    "unique_residues_with_gaps = len(set(''.join([''.join(column) for column in transposed_alignment])))\n",
    "unique_residues_without_gaps = len(set(''.join([''.join(column) for column in transposed_alignment])) - set('-'))\n",
    "\n",
    "# Normalized entropy values\n",
    "normalized_entropies_with_gaps = normalize_entropy(entropies, unique_residues_with_gaps)\n",
    "normalized_entropies_without_gaps = normalize_entropy(entropies, unique_residues_without_gaps)\n",
    "\n",
    "# Function to find top 10 positions with lowest entropy excluding gaps\n",
    "def find_lowest_entropy_positions(normalized_entropies, alignment, num_positions=10):\n",
    "    sorted_positions = sorted(range(len(normalized_entropies)), key=lambda i: normalized_entropies[i])\n",
    "    lowest_entropy_positions = []\n",
    "    for pos in sorted_positions:\n",
    "        if len(lowest_entropy_positions) >= num_positions:\n",
    "            break\n",
    "        column = set(alignment[pos])\n",
    "        # Exclude positions that are only gaps\n",
    "        if '-' in column:\n",
    "            column.remove('-')\n",
    "        if column:  # If there are amino acids in the column\n",
    "            lowest_entropy_positions.append((pos, normalized_entropies[pos], column))\n",
    "    return lowest_entropy_positions\n",
    "\n",
    "# Find top 10 positions for both cases\n",
    "top_positions_with_gaps = find_lowest_entropy_positions(normalized_entropies_with_gaps, transposed_alignment)\n",
    "top_positions_without_gaps = find_lowest_entropy_positions(normalized_entropies_without_gaps, transposed_alignment)\n",
    "\n",
    "# Print the positions, their normalized entropy values, and the corresponding amino acids\n",
    "print(\"Top 10 positions with lowest entropy (including gaps):\")\n",
    "for pos, entropy, amino_acids in top_positions_with_gaps:\n",
    "    print(f\"Position {pos + 1}: Normalized Entropy = {entropy:.4f}, Amino Acids = {', '.join(amino_acids)}\")\n",
    "\n",
    "print(\"\\nTop 10 positions with lowest entropy (excluding gaps):\")\n",
    "for pos, entropy, amino_acids in top_positions_without_gaps:\n",
    "    print(f\"Position {pos + 1}: Normalized Entropy = {entropy:.4f}, Amino Acids = {', '.join(amino_acids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed15523-07d4-4bdd-93f9-76d34cc4be74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import AlignIO\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "# Function to calculate probability distribution for a given column\n",
    "def probability_distribution(column):\n",
    "    counts = Counter(column)\n",
    "    total = sum(counts.values())\n",
    "    return {residue: count / total for residue, count in counts.items()}\n",
    "\n",
    "# Function to calculate cross-entropy between two columns\n",
    "def cross_entropy(dist1, dist2):\n",
    "    residues = set(dist1.keys()).union(dist2.keys())\n",
    "    return -sum(dist1.get(residue, 0) * math.log2(dist2.get(residue, 0) if dist2.get(residue, 0) > 0 else 1) for residue in residues)\n",
    "\n",
    "# Load the aligned sequences\n",
    "try:\n",
    "    aligned_sequences = AlignIO.read('aligned_B.fasta', 'fasta')\n",
    "except Exception as e:\n",
    "    print(f\"Error loading alignment file: {e}\")\n",
    "    raise\n",
    "\n",
    "# Convert aligned sequences to a list of strings\n",
    "aligned_seq_str = [str(record.seq) for record in aligned_sequences]\n",
    "\n",
    "# Check if the alignment is correctly loaded\n",
    "if not aligned_seq_str:\n",
    "    print(\"No sequences found in the alignment.\")\n",
    "else:\n",
    "    print(f\"Loaded {len(aligned_seq_str)} sequences.\")\n",
    "\n",
    "# Transpose the alignment for column-wise processing\n",
    "transposed_alignment = np.array([list(seq) for seq in aligned_seq_str]).T\n",
    "\n",
    "# Calculate probability distributions for each column\n",
    "prob_distributions = [probability_distribution(column) for column in transposed_alignment]\n",
    "\n",
    "# Calculate cross-entropy for each pair of columns\n",
    "cross_entropy_values = np.zeros((len(prob_distributions), len(prob_distributions)))\n",
    "for i, dist1 in enumerate(prob_distributions):\n",
    "    for j, dist2 in enumerate(prob_distributions):\n",
    "        cross_entropy_values[i, j] = cross_entropy(dist1, dist2)\n",
    "\n",
    "# Normalize cross-entropy values\n",
    "max_entropy = math.log2(len(prob_distributions))\n",
    "normalized_cross_entropy = cross_entropy_values / max_entropy\n",
    "\n",
    "# Print cross-entropy values\n",
    "print(\"Cross-Entropy Values:\")\n",
    "for i in range(len(cross_entropy_values)):\n",
    "    for j in range(len(cross_entropy_values)):\n",
    "        print(f\"Cross-Entropy between positions {i+1} and {j+1}: {cross_entropy_values[i, j]:.4f}, Normalized: {normalized_cross_entropy[i, j]:.4f}\")\n",
    "\n",
    "# Create a heatmap using Plotly\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=cross_entropy_values,\n",
    "    x=[f\"Pos {i+1}\" for i in range(len(cross_entropy_values))],\n",
    "    y=[f\"Pos {j+1}\" for j in range(len(cross_entropy_values))],\n",
    "    colorscale='Viridis'))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Cross-Entropy Heatmap between Positions in Protein Alignment',\n",
    "    xaxis_nticks=36,\n",
    "    yaxis_nticks=36,    \n",
    "    width=1000,  \n",
    "    height=1000,  \n",
    "    margin=dict(l=100, r=100, t=100, b=100)  \n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeef6fd-fb1d-4943-a1d8-4d096839c729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Bio import AlignIO\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import plotly.graph_objects as go\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "def encode_sequences(sequences, alphabet='ACDEFGHIKLMNPQRSTVWY-'):\n",
    "    char_to_int = {c: i for i, c in enumerate(alphabet)}\n",
    "    encoded_seqs = [[char_to_int.get(char, -1) for char in seq] for seq in sequences]\n",
    "    return np.array(encoded_seqs, dtype=int)\n",
    "\n",
    "def calculate_mi_for_position(encoded_seqs, i):\n",
    "    X = np.delete(encoded_seqs, i, axis=1)\n",
    "    y = encoded_seqs[:, i]\n",
    "    mi_score = mutual_info_classif(X, y, discrete_features=True)\n",
    "    return np.insert(mi_score, i, 0)  # Insert 0 at the ith position for the diagonal\n",
    "\n",
    "def main():\n",
    "    aligned_sequences = AlignIO.read(\"aligned_B.fasta\", \"fasta\")\n",
    "    sequences = [str(record.seq) for record in aligned_sequences]\n",
    "    encoded_seqs = encode_sequences(sequences)\n",
    "\n",
    "    num_features = encoded_seqs.shape[1]\n",
    "    mi_matrix = np.zeros((num_features, num_features))\n",
    "\n",
    "    with Pool(processes=cpu_count()) as pool:\n",
    "        results = pool.starmap(calculate_mi_for_position, [(encoded_seqs, i) for i in range(num_features)])\n",
    "\n",
    "    for i, mi_scores in enumerate(results):\n",
    "        mi_matrix[i, :] = mi_scores\n",
    "\n",
    "    # Normalize the mutual information matrix using MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    mi_matrix_normalized = scaler.fit_transform(mi_matrix)\n",
    "\n",
    "    # Create a heatmap using Plotly\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=mi_matrix_normalized,\n",
    "        x=[f\"Pos {i+1}\" for i in range(num_features)],\n",
    "        y=[f\"Pos {i+1}\" for i in range(num_features)],\n",
    "        colorscale='Portland',  # Changed to Viridis for better color contrast\n",
    "        zmin=0, zmax=1  # Set the scale from 0 to 1\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='MinMax Scaled Mutual Information Heatmap',\n",
    "        xaxis_title=\"Position\",\n",
    "        yaxis_title=\"Position\",\n",
    "        width=900,\n",
    "        height=900\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922f2e05-c442-4dff-a9ac-330a6edaa627",
   "metadata": {},
   "source": [
    "## HLA-C "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ac4559-04fd-46bf-9352-19c0456d8f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import AlignIO\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "# Function to calculate Shannon entropy for a given column in the alignment\n",
    "def shannon_entropy(column):\n",
    "    counts = Counter(column)\n",
    "    probabilities = [freq / len(column) for freq in counts.values()]\n",
    "    entropy = -sum(p * math.log2(p) if p > 0 else 0 for p in probabilities)\n",
    "    return entropy\n",
    "\n",
    "# Function to normalize entropy based on the number of residues (with and without gaps)\n",
    "def normalize_entropy(entropies, num_residues):\n",
    "    max_entropy = math.log2(num_residues)\n",
    "    normalized_entropies = [e / max_entropy for e in entropies]\n",
    "    return normalized_entropies\n",
    "\n",
    "# Load the aligned sequences using Biopython\n",
    "aligned_sequences = AlignIO.read('aligned_C.fasta', 'fasta')\n",
    "\n",
    "# Convert aligned sequences to a list of strings for easier processing\n",
    "aligned_seq_str = [str(record.seq) for record in aligned_sequences]\n",
    "\n",
    "# Transpose the alignment for column-wise processing\n",
    "transposed_alignment = np.array([list(seq) for seq in aligned_seq_str]).T\n",
    "\n",
    "# Calculate entropy for each column\n",
    "entropies = [shannon_entropy(column) for column in transposed_alignment]\n",
    "\n",
    "# Find the number of unique residues (with and without gaps)\n",
    "unique_residues_with_gaps = len(set(''.join([''.join(column) for column in transposed_alignment])))\n",
    "unique_residues_without_gaps = len(set(''.join([''.join(column) for column in transposed_alignment])) - set('-'))\n",
    "\n",
    "# Normalized entropy values\n",
    "normalized_entropies_with_gaps = normalize_entropy(entropies, unique_residues_with_gaps)\n",
    "normalized_entropies_without_gaps = normalize_entropy(entropies, unique_residues_without_gaps)\n",
    "\n",
    "# Print entropy values for each position\n",
    "for i, (entropy, norm_with_gaps, norm_without_gaps) in enumerate(zip(entropies, normalized_entropies_with_gaps, normalized_entropies_without_gaps)):\n",
    "    print(f\"Position {i+1}: Entropy = {entropy:.4f}, Normalized (with gaps) = {norm_with_gaps:.4f}, Normalized (without gaps) = {norm_without_gaps:.4f}\")\n",
    "\n",
    "# Overall normalized entropy\n",
    "overall_entropy_with_gaps = np.mean(normalized_entropies_with_gaps)\n",
    "overall_entropy_without_gaps = np.mean(normalized_entropies_without_gaps)\n",
    "\n",
    "print(f\"\\nOverall Normalized Entropy (with gaps): {overall_entropy_with_gaps:.4f}\")\n",
    "print(f\"Overall Normalized Entropy (without gaps): {overall_entropy_without_gaps:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1618e9-a24e-4041-bf89-699c76318ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import AlignIO\n",
    "from collections import Counter\n",
    "\n",
    "def format_output(consensus, line_length=60):\n",
    "    \"\"\"Format the positions and consensus sequence into two aligned lines.\"\"\"\n",
    "    formatted_str = \"\"\n",
    "    for i in range(0, len(consensus), line_length):\n",
    "        # Generate the position line\n",
    "        pos_line = ''.join(str(j) if j % 10 == 0 else ' ' for j in range(i, i + line_length))\n",
    "\n",
    "        # Generate the consensus sequence line\n",
    "        seq_line = ''.join(consensus[i:i+line_length])\n",
    "\n",
    "        # Add the two lines to the formatted string\n",
    "        formatted_str += pos_line + '\\n' + seq_line + '\\n\\n'\n",
    "    return formatted_str\n",
    "\n",
    "# Load the alignment file\n",
    "alignment = AlignIO.read(\"aligned_C.fasta\", \"fasta\")\n",
    "\n",
    "# Initialize the consensus sequence list\n",
    "consensus_seq = []\n",
    "\n",
    "# Iterate over each column in the alignment\n",
    "for i in range(len(alignment[0])):\n",
    "    column = [record.seq[i] for record in alignment]  # Extract the column\n",
    "    most_common = Counter(column).most_common(1)[0][0]  # Find the most common character in the column\n",
    "    consensus_seq.append(most_common)\n",
    "\n",
    "# Format the sequence and positions for better readability\n",
    "formatted_output = format_output(consensus_seq)\n",
    "\n",
    "# Print the formatted consensus sequence with positions\n",
    "print(formatted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1b4c2d-cfd6-4a7c-bd7f-0bfffce2d40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import AlignIO\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "# Function definitions (shannon_entropy, normalize_entropy) remain the same as before\n",
    "\n",
    "# Load the aligned sequences using Biopython\n",
    "aligned_sequences = AlignIO.read('aligned_C.fasta', 'fasta')\n",
    "\n",
    "# Convert aligned sequences to a list of strings\n",
    "aligned_seq_str = [str(record.seq) for record in aligned_sequences]\n",
    "\n",
    "# Transpose the alignment for column-wise processing\n",
    "transposed_alignment = np.array([list(seq) for seq in aligned_seq_str]).T\n",
    "\n",
    "# Calculate entropy for each column\n",
    "entropies = [shannon_entropy(column) for column in transposed_alignment]\n",
    "\n",
    "# Find the number of unique residues (with and without gaps)\n",
    "unique_residues_with_gaps = len(set(''.join([''.join(column) for column in transposed_alignment])))\n",
    "unique_residues_without_gaps = len(set(''.join([''.join(column) for column in transposed_alignment])) - set('-'))\n",
    "\n",
    "# Normalized entropy values\n",
    "normalized_entropies_with_gaps = normalize_entropy(entropies, unique_residues_with_gaps)\n",
    "normalized_entropies_without_gaps = normalize_entropy(entropies, unique_residues_without_gaps)\n",
    "\n",
    "# Function to find top 10 positions with lowest entropy excluding gaps\n",
    "def find_lowest_entropy_positions(normalized_entropies, alignment, num_positions=10):\n",
    "    sorted_positions = sorted(range(len(normalized_entropies)), key=lambda i: normalized_entropies[i])\n",
    "    lowest_entropy_positions = []\n",
    "    for pos in sorted_positions:\n",
    "        if len(lowest_entropy_positions) >= num_positions:\n",
    "            break\n",
    "        column = set(alignment[pos])\n",
    "        # Exclude positions that are only gaps\n",
    "        if '-' in column:\n",
    "            column.remove('-')\n",
    "        if column:  # If there are amino acids in the column\n",
    "            lowest_entropy_positions.append((pos, normalized_entropies[pos], column))\n",
    "    return lowest_entropy_positions\n",
    "\n",
    "# Find top 10 positions for both cases\n",
    "top_positions_with_gaps = find_lowest_entropy_positions(normalized_entropies_with_gaps, transposed_alignment)\n",
    "top_positions_without_gaps = find_lowest_entropy_positions(normalized_entropies_without_gaps, transposed_alignment)\n",
    "\n",
    "# Print the positions, their normalized entropy values, and the corresponding amino acids\n",
    "print(\"Top 10 positions with lowest entropy (including gaps):\")\n",
    "for pos, entropy, amino_acids in top_positions_with_gaps:\n",
    "    print(f\"Position {pos + 1}: Normalized Entropy = {entropy:.4f}, Amino Acids = {', '.join(amino_acids)}\")\n",
    "\n",
    "print(\"\\nTop 10 positions with lowest entropy (excluding gaps):\")\n",
    "for pos, entropy, amino_acids in top_positions_without_gaps:\n",
    "    print(f\"Position {pos + 1}: Normalized Entropy = {entropy:.4f}, Amino Acids = {', '.join(amino_acids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d0ea12-ed30-459e-ac10-d148804b8f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import AlignIO\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "# Function to calculate probability distribution for a given column\n",
    "def probability_distribution(column):\n",
    "    counts = Counter(column)\n",
    "    total = sum(counts.values())\n",
    "    return {residue: count / total for residue, count in counts.items()}\n",
    "\n",
    "# Function to calculate cross-entropy between two columns\n",
    "def cross_entropy(dist1, dist2):\n",
    "    residues = set(dist1.keys()).union(dist2.keys())\n",
    "    return -sum(dist1.get(residue, 0) * math.log2(dist2.get(residue, 0) if dist2.get(residue, 0) > 0 else 1) for residue in residues)\n",
    "\n",
    "# Load the aligned sequences\n",
    "try:\n",
    "    aligned_sequences = AlignIO.read('aligned_C.fasta', 'fasta')\n",
    "except Exception as e:\n",
    "    print(f\"Error loading alignment file: {e}\")\n",
    "    raise\n",
    "\n",
    "# Convert aligned sequences to a list of strings\n",
    "aligned_seq_str = [str(record.seq) for record in aligned_sequences]\n",
    "\n",
    "# Check if the alignment is correctly loaded\n",
    "if not aligned_seq_str:\n",
    "    print(\"No sequences found in the alignment.\")\n",
    "else:\n",
    "    print(f\"Loaded {len(aligned_seq_str)} sequences.\")\n",
    "\n",
    "# Transpose the alignment for column-wise processing\n",
    "transposed_alignment = np.array([list(seq) for seq in aligned_seq_str]).T\n",
    "\n",
    "# Calculate probability distributions for each column\n",
    "prob_distributions = [probability_distribution(column) for column in transposed_alignment]\n",
    "\n",
    "# Calculate cross-entropy for each pair of columns\n",
    "cross_entropy_values = np.zeros((len(prob_distributions), len(prob_distributions)))\n",
    "for i, dist1 in enumerate(prob_distributions):\n",
    "    for j, dist2 in enumerate(prob_distributions):\n",
    "        cross_entropy_values[i, j] = cross_entropy(dist1, dist2)\n",
    "\n",
    "# Normalize cross-entropy values\n",
    "max_entropy = math.log2(len(prob_distributions))\n",
    "normalized_cross_entropy = cross_entropy_values / max_entropy\n",
    "\n",
    "# Print cross-entropy values\n",
    "#print(\"Cross-Entropy Values:\")\n",
    "#for i in range(len(cross_entropy_values)):\n",
    "#    for j in range(len(cross_entropy_values)):\n",
    "#        print(f\"Cross-Entropy between positions {i+1} and {j+1}: {cross_entropy_values[i, j]:.4f}, Normalized: {normalized_cross_entropy[i, j]:.4f}\")\n",
    "\n",
    "# Create a heatmap using Plotly\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=cross_entropy_values,\n",
    "    x=[f\"Pos {i+1}\" for i in range(len(cross_entropy_values))],\n",
    "    y=[f\"Pos {j+1}\" for j in range(len(cross_entropy_values))],\n",
    "    colorscale='Viridis'))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Cross-Entropy Heatmap between Positions in Protein Alignment',\n",
    "    xaxis_nticks=36,\n",
    "    yaxis_nticks=36,    \n",
    "    width=1000,  \n",
    "    height=1000,  \n",
    "    margin=dict(l=100, r=100, t=100, b=100)  \n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae8ed8c-808b-4f1e-85aa-e440f3559e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Bio import AlignIO\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import plotly.graph_objects as go\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "def encode_sequences(sequences, alphabet='ACDEFGHIKLMNPQRSTVWY-'):\n",
    "    char_to_int = {c: i for i, c in enumerate(alphabet)}\n",
    "    encoded_seqs = [[char_to_int.get(char, -1) for char in seq] for seq in sequences]\n",
    "    return np.array(encoded_seqs, dtype=int)\n",
    "\n",
    "def calculate_mi_for_position(encoded_seqs, i):\n",
    "    X = np.delete(encoded_seqs, i, axis=1)\n",
    "    y = encoded_seqs[:, i]\n",
    "    mi_score = mutual_info_classif(X, y, discrete_features=True)\n",
    "    return np.insert(mi_score, i, 0)  # Insert 0 at the ith position for the diagonal\n",
    "\n",
    "def main():\n",
    "    aligned_sequences = AlignIO.read(\"aligned_C.fasta\", \"fasta\")\n",
    "    sequences = [str(record.seq) for record in aligned_sequences]\n",
    "    encoded_seqs = encode_sequences(sequences)\n",
    "\n",
    "    num_features = encoded_seqs.shape[1]\n",
    "    mi_matrix = np.zeros((num_features, num_features))\n",
    "\n",
    "    with Pool(processes=cpu_count()) as pool:\n",
    "        results = pool.starmap(calculate_mi_for_position, [(encoded_seqs, i) for i in range(num_features)])\n",
    "\n",
    "    for i, mi_scores in enumerate(results):\n",
    "        mi_matrix[i, :] = mi_scores\n",
    "\n",
    "    # Normalize the mutual information matrix using MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    mi_matrix_normalized = scaler.fit_transform(mi_matrix)\n",
    "\n",
    "    # Create a heatmap using Plotly\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=mi_matrix_normalized,\n",
    "        x=[f\"Pos {i+1}\" for i in range(num_features)],\n",
    "        y=[f\"Pos {i+1}\" for i in range(num_features)],\n",
    "        colorscale='Portland',  # Changed to Viridis for better color contrast\n",
    "        zmin=0, zmax=1  # Set the scale from 0 to 1\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='MinMax Scaled Mutual Information Heatmap',\n",
    "        xaxis_title=\"Position\",\n",
    "        yaxis_title=\"Position\",\n",
    "        width=900,\n",
    "        height=900\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
